{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import shutil \n",
    "\n",
    "batch_size= 32\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('../datasets/mnist', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                                torchvision.transforms.Resize([32, 32]),\n",
    "                                torchvision.transforms.ToTensor(),\n",
    "                                #torchvision.transforms.Normalize(\n",
    "                                # (0.5,), (0.5,))\n",
    "                             ])),\n",
    "  batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('../datasets/mnist', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                                torchvision.transforms.Resize([32, 32]),\n",
    "                                torchvision.transforms.ToTensor(),\n",
    "                                #torchvision.transforms.Normalize(\n",
    "                                # (0.5,), (0.5,))\n",
    "                             ])),\n",
    "  batch_size=16, shuffle=False, drop_last= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import shutil \n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from modules.models.forward_H import modelH\n",
    "from modules.models.preprocess_H_weights import ifft, fft\n",
    "\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=5\n",
    "H_complex_init =False\n",
    "H_weight_preprocess=  torch.abs #None\n",
    "m_inc_proc =inc_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_generator = modelH(T, 32, H_weight_preprocess, H_complex_init, device).to(device)\n",
    "opt_H= torch.optim.Adam(H_generator.parameters(), lr= 2)\n",
    "\n",
    "\n",
    "for e in range(10):\n",
    "    opt_H.zero_grad()\n",
    "    out = H_generator()\n",
    "    loss = torch.abs(out-torch.ones_like(out)).sum()\n",
    "    loss.backward()\n",
    "    opt_H.step()\n",
    "    \n",
    "    plt.imshow(H_generator()[0,0].cpu().detach().numpy(), vmin=0, vmax=1, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r  ../aim2.zip ../aim2 -x ../aim2/figs/**\\*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6M\t../aim2.zip\n"
     ]
    }
   ],
   "source": [
    "!du -sh ../aim2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May 23 03:46:50 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.23.05    Driver Version: 455.23.05    CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  On   | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    34W / 250W |   2474MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     85239      C   ...a/envs/deepTFM/bin/python     1157MiB |\n",
      "|    0   N/A  N/A     86460      C   ...a/envs/deepTFM/bin/python     1313MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepTFM",
   "language": "python",
   "name": "deeptfm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
