{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from main_reconstruction_swinIRwCustomUp_wforward import safe_do_exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name= 'bbbcHumanMCF7cellsW4_swinIRwCustomV2_EvalHtOurUpsample'\n",
    "\n",
    "exp_dir= f'../figs/{name}' #'/n/holylfs/LABS/wadduwage_lab/Lab/uom_Udith/results/aim2/figs'\n",
    "save_dir_special_root = f'../figs/{name}' #f'/n/holylfs/LABS/wadduwage_lab/Lab/uom_Udith/results/aim2/figs/{name}'\n",
    "\n",
    "!rm -rf $exp_dir\n",
    "!mkdir $exp_dir\n",
    "\n",
    "!rm -rf $save_dir_special_root\n",
    "!mkdir $save_dir_special_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of total experiments : 1\n",
      "running  -> ../figs/bbbcHumanMCF7cellsW4_swinIRwCustomV2_EvalHtOurUpsample/name(bbbcHumanMCF7cellsW4)@rotation_lambda(10000.0)@lambda_scale_factor(3)@T(1)@img_size(64)@num_samples_train(50)@num_samples_valtest(25)@batch_size_train(8)\n",
      "Overide opts :  ['NAME', 'exp_idx(1)', 'GENERAL.device', 'cuda:1', 'GENERAL.save_dir', '../figs/bbbcHumanMCF7cellsW4_swinIRwCustomV2_EvalHtOurUpsample/name(bbbcHumanMCF7cellsW4)@rotation_lambda(10000.0)@lambda_scale_factor(3)@T(1)@img_size(64)@num_samples_train(50)@num_samples_valtest(25)@batch_size_train(8)', 'TRAIN.show_results_epoch', '1', 'TRAIN.epochs', '3', 'DATASET.name', 'bbbcHumanMCF7cellsW4', 'MODEL.MODEL_A.rotation_lambda', '10000.0', 'MODEL.MODEL_A.lambda_scale_factor', '3', 'MODEL.MODEL_H.T', '1', 'DATASET.img_size', '64', 'DATASET.num_samples_train', '50', 'DATASET.num_samples_valtest', '25', 'DATASET.batch_size_train', '8']\n",
      "DATASET:\n",
      "  batch_size_train: 8\n",
      "  delta: 1e-06\n",
      "  img_channels: 1\n",
      "  img_size: 64\n",
      "  name: bbbcHumanMCF7cellsW4\n",
      "  num_samples_train: 50\n",
      "  num_samples_valtest: 25\n",
      "GENERAL:\n",
      "  device: cuda:1\n",
      "  other_opt_dir: None\n",
      "  save_dir: ../figs/bbbcHumanMCF7cellsW4_swinIRwCustomV2_EvalHtOurUpsample/name(bbbcHumanMCF7cellsW4)@rotation_lambda(10000.0)@lambda_scale_factor(3)@T(1)@img_size(64)@num_samples_train(50)@num_samples_valtest(25)@batch_size_train(8)\n",
      "  torch_seed: 10\n",
      "MODEL:\n",
      "  MODEL_A:\n",
      "    exPSF: impulse(side_len=5)\n",
      "    lambda_scale_factor: 3\n",
      "    noise: True\n",
      "    readnoise_std: 0.0\n",
      "    rotation_lambda: 10000.0\n",
      "    sPSF: impulse(side_len=5)\n",
      "    shift_lambda_real: 10.0\n",
      "  MODEL_DECODER:\n",
      "    channel_list: [24, 12, 8, 4, 2]\n",
      "    connect_forward_inverse: no_skips\n",
      "    custom_upsampling_bias: True\n",
      "    last_activation: sigmoid\n",
      "    lr_decoder: 0.001\n",
      "    name: genv1\n",
      "    upsample_net: custom_v2\n",
      "    upsample_net_init_method: xavier_normal\n",
      "  MODEL_H:\n",
      "    H_activation: sigmoid_custom\n",
      "    H_init: randn_FourierBased\n",
      "    H_weight_preprocess: ifft_2d_with_fftshift_real\n",
      "    T: 1\n",
      "    initialization_bias: 0\n",
      "    lr_H: 0.0\n",
      "NAME: exp_idx(1)\n",
      "TRAIN:\n",
      "  classifier: None\n",
      "  criterion: nn.L1Loss().to(device)\n",
      "  epochs: 3\n",
      "  m_inc_proc: inc_m_class(epoch_threshold= 80, epoch_steps= 10)\n",
      "  rescale_for_classifier: None\n",
      "  show_results_epoch: 1\n",
      "  train_H_iter: 1\n",
      "  train_model_iter: 1\n",
      "skip connection between FORWARD and INVERSE models :: no_skips\n",
      "MODEL_H : enable_train ::: False (derived from lr_H)\n",
      "len(results_saving_folder) : 158 (<= 255)\n",
      "total images found in: /home/udith/udith_works/datasets/bbbcHumanMCF7cells/preprocessed/w4/train -> 206976\n",
      "total images found in: /home/udith/udith_works/datasets/bbbcHumanMCF7cells/preprocessed/w4/val -> 2112\n",
      "total images found in: /home/udith/udith_works/datasets/bbbcHumanMCF7cells/preprocessed/w4/test -> 2112\n",
      "dataset lenths : 50 | 25 | 25\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset value range :  0.007844130508601665 0.7137258648872375\n",
      "Ht range :  tensor(0.0229, device='cuda:1') tensor(0.9827, device='cuda:1')\n",
      "** default other opt dir is used : None\n",
      "upsample net (custom_v2) is created succesfully inside SwinIR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../adversarial_learning/swinIRwCustomUpwforward_support_files/models_define.py:129: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  opt = yaml.load(file)\n",
      "/home/udith/miniconda3/envs/deepTFM/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1640811805959/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass this initialization! Initialization was done during network defination!\n",
      "Initialization method [orthogonal + uniform], gain is [0.20]\n",
      "upsample net (custom_v2) is created succesfully inside SwinIR\n",
      "Pass this initialization! Initialization was done during network defination!\n",
      "Sequential(\n",
      "  (child0): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (child1): Sequential(\n",
      "    (0): ReLU(inplace=True)\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (child2): Sequential(\n",
      "    (0): ReLU(inplace=True)\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (child3): Sequential(\n",
      "    (0): ReLU(inplace=True)\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (child4): Sequential(\n",
      "    (0): ReLU(inplace=True)\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "feature_layer: [2, 7, 16, 25, 34]  with weights: [0.1, 0.1, 1.0, 1.0, 1.0]\n",
      "Params [modelH.weights] will not optimize.\n",
      "device : cuda:1\n",
      "m : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/udith/miniconda3/envs/deepTFM/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "/home/udith/miniconda3/envs/deepTFM/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 48.00 MiB (GPU 1; 23.65 GiB total capacity; 2.36 GiB already allocated; 49.88 MiB free; 2.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-351a16c04c3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0msafe_do_exps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneral_opts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_special\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_only\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcount_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir_special_root\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msave_dir_special_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/udith_works/DabbaMu-DEEP-TFM/aim2/current_exps_notebooks/main_reconstruction_swinIRwCustomUp_wforward.py\u001b[0m in \u001b[0;36msafe_do_exps\u001b[0;34m(exps_dict, general_opts, device, exp_dir, save_special, count_only, save_dir_special_root)\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_folder_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_special\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_special\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             '''\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/udith_works/DabbaMu-DEEP-TFM/aim2/train/reconstruction_swinIRwCustomUp_wforward.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(config_file, opts, save_special, save_dir_special)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_upsample_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnect_forward_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mopt_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_H\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_results_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_model_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_H_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_inc_proc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrescale_for_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_special\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir_special\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/udith_works/DabbaMu-DEEP-TFM/aim2/modules/train_utils/reconstruction_swinIRwCustomUp_wforward.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model_decoder, model_decoder_upsample, model_A, model_H, connect_forward_inverse, criterion, opt, train_loader, test_loader, device, epochs, show_results_epoch, train_model_iter, train_H_iter, m_inc_proc, save_dir, classifier, rescale_for_classifier, save_special_bool, cfg, save_dir_special)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mstart_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mlosses_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt_down\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_decoder_upsample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_model_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_H_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnect_forward_inverse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mend_train\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/udith_works/DabbaMu-DEEP-TFM/aim2/modules/train_utils/reconstruction_swinIRwCustomUp_wforward.py\u001b[0m in \u001b[0;36mloop\u001b[0;34m(device, loader, model_decoder, model_decoder_upsample, model_A, model_H, criterion, opt, type_, losses, epoch, m, train_model_iter, train_H_iter, metrics, connect_forward_inverse)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mmodel_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mmodel_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'm'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'H'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mmodel_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_H\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#optimize both model_decoder and Ht\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mX_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/udith_works/DabbaMu-DEEP-TFM/aim2/adversarial_learning/swinIRwCustomUpwforward_support_files/models_define.py\u001b[0m in \u001b[0;36moptimize_parameters\u001b[0;34m(self, current_step, other_optimizers)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetG_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0mloss_G_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/udith_works/DabbaMu-DEEP-TFM/aim2/adversarial_learning/swinIRwCustomUpwforward_support_files/models_define.py\u001b[0m in \u001b[0;36mnetG_forward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;31m# ----------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnetG_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHt\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myt_down\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myt_down\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepTFM/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/udith_works/DabbaMu-DEEP-TFM/aim2/adversarial_learning/swinIRwCustomUpwforward_support_files/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, m)\u001b[0m\n\u001b[1;32m    871\u001b[0m             \u001b[0;31m# for image denoising and JPEG compression artifact reduction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0mx_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_first\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_after_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx_first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_last\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/udith_works/DabbaMu-DEEP-TFM/aim2/adversarial_learning/swinIRwCustomUpwforward_support_files/models.py\u001b[0m in \u001b[0;36mforward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# B L C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepTFM/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/udith_works/DabbaMu-DEEP-TFM/aim2/adversarial_learning/swinIRwCustomUpwforward_support_files/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, x_size)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_unembed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresidual_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mflops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepTFM/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/udith_works/DabbaMu-DEEP-TFM/aim2/adversarial_learning/swinIRwCustomUpwforward_support_files/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, x_size)\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepTFM/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/udith_works/DabbaMu-DEEP-TFM/aim2/adversarial_learning/swinIRwCustomUpwforward_support_files/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, x_size)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mattn_windows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_windows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# nW*B, window_size*window_size, C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0mattn_windows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_windows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;31m# merge windows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepTFM/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/udith_works/DabbaMu-DEEP-TFM/aim2/adversarial_learning/swinIRwCustomUpwforward_support_files/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 1; 23.65 GiB total capacity; 2.36 GiB already allocated; 49.88 MiB free; 2.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "count_only = False\n",
    "\n",
    "device = 'cuda:1'\n",
    "\n",
    "exps = {\n",
    "        'DATASET.name': ['bbbcHumanMCF7cellsW4'],\n",
    "    \n",
    "        'MODEL.MODEL_A.rotation_lambda': ['10000.0'],\n",
    "        'MODEL.MODEL_A.lambda_scale_factor': ['3'],\n",
    "        'MODEL.MODEL_H.T': ['1'], \n",
    "        #'MODEL.MODEL_H.lr_H': ['1.0'],\n",
    "    \n",
    "        'DATASET.img_size':  ['64'], #256\n",
    "        'DATASET.num_samples_train': ['50'], #'10000-> 1400 sec/ epoch' , 3000-> 440 sec/ epoch (18.3hrs/ exp)  \n",
    "        'DATASET.num_samples_valtest': ['25'],\n",
    "        'DATASET.batch_size_train': ['8'], #32\n",
    "}\n",
    "\n",
    "general_opts= ['TRAIN.show_results_epoch', '1', #5\n",
    "                'TRAIN.epochs', '3']  #150\n",
    "\n",
    "\n",
    "safe_do_exps(exps, general_opts, device, exp_dir = exp_dir, save_special= True, count_only= count_only, save_dir_special_root= save_dir_special_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c245a2e360dbb42312e38a2d32c9e2363c0490331dbfe238722d1a7e87cebc70"
  },
  "kernelspec": {
   "display_name": "deepTFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
