{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import shutil\n",
    "from train_segmentation import run\n",
    "import os\n",
    "import itertools\n",
    "import glob\n",
    "\n",
    "def write_errormsg2file(msg, error_file_name):\n",
    "    if not os.path.isfile(error_file_name):\n",
    "        with open(error_file_name, 'w') as f:\n",
    "            f.write(f'error : {msg}\\n')\n",
    "    else:\n",
    "        with open(error_file_name, 'a') as f:\n",
    "            f.write(f'error : {msg}\\n')\n",
    "           \n",
    "    \n",
    "def safe_do_exps(exps_dict= None, general_opts= None, device= None, exp_dir = '../figs/test', save_special= False, count_only= True, save_dir_special_root=None):    \n",
    "    exp_idx = 0\n",
    "    keys= list(exps.keys())\n",
    "    \n",
    "    val_list_list= []\n",
    "    key_list = [] #eg: 'MODEL.MODEL_A.rotation_lambda'\n",
    "    key_suffix_list= [] # eg: 'rotation_lambda'\n",
    "    \n",
    "    for key, val_list in exps_dict.items():\n",
    "        key_list.append(key)\n",
    "        key_suffix_list.append(key.split('.')[-1])\n",
    "        \n",
    "        val_list_list.append(val_list)\n",
    "        \n",
    "    attr_combination_list = [list(s) for s in itertools.product(*val_list_list)]\n",
    "    \n",
    "    print(f'number of total experiments : {len(attr_combination_list)}')\n",
    "    \n",
    "    count_already_trained=0\n",
    "    count_train_from_begining=0\n",
    "    count_deleted = 0\n",
    "    for attr_combination in attr_combination_list:\n",
    "        save_dir = f'{exp_dir}/'\n",
    "        opts= []\n",
    "        for idx in range(len(attr_combination)):\n",
    "            opts += [key_list[idx], attr_combination[idx]]\n",
    "            attr= attr_combination[idx]\n",
    "            \n",
    "            #####\n",
    "            attr_is_list= False\n",
    "            try:attr_is_list = isinstance(eval(attr), list)\n",
    "            except:pass\n",
    "            if attr_is_list:\n",
    "                attr= '_'.join(list(map(str, eval(attr)))) ## [, ] should not be in the directory name because glob is sensitive to that !\n",
    "            #####\n",
    "            \n",
    "            save_dir+= f'{key_suffix_list[idx]}({attr})@'\n",
    "    \n",
    "        save_dir = save_dir[:-1] # remove last '@' \n",
    "\n",
    "        exp_idx+=1\n",
    "        opts_other= ['NAME', f'exp_idx({exp_idx})', \n",
    "                     'GENERAL.device', device, \n",
    "                     'GENERAL.save_dir', save_dir\n",
    "                    ]\n",
    "                     \n",
    "        opts_other+= general_opts\n",
    "\n",
    "        opts = opts_other + opts\n",
    "\n",
    "        if os.path.isdir(save_dir):\n",
    "            if 'TRAIN.epochs' in opts:\n",
    "                epochs_idx = opts.index('TRAIN.epochs')\n",
    "                epochs = int(opts[epochs_idx+1]) # IF THIS GIVES ERROR -> THERE IS A PROBLEM\n",
    "                \n",
    "                if len(glob.glob(f'{save_dir}/{epochs}_*.jpg'))!=0:\n",
    "                    count_already_trained+=1\n",
    "                    print(f'PASSING (already trained) -> {save_dir}')\n",
    "                    continue\n",
    "                else:\n",
    "                    count_train_from_begining+=1\n",
    "                    count_deleted += 1\n",
    "                    print(f'deleting -> {save_dir}')\n",
    "                    if not count_only:shutil.rmtree(save_dir)\n",
    "            else:\n",
    "                count_train_from_begining+=1\n",
    "                count_deleted += 1\n",
    "                print(f'deleting -> {save_dir}')\n",
    "                if not count_only:shutil.rmtree(save_dir)         \n",
    "        else:\n",
    "            count_train_from_begining+=1\n",
    "                \n",
    "        save_folder_name= save_dir.split('/')[-1]\n",
    "        \n",
    "        if not count_only:\n",
    "            print(f'running  -> {save_dir}')\n",
    "            if len(save_folder_name)>255:\n",
    "                print(f'\\nFolder length is too long: len(results_saving_folder) -> {len(save_folder_name)} (<= 255)')\n",
    "                print(save_folder_name)\n",
    "\n",
    "            #run(opts= opts, save_special=save_special)\n",
    "\n",
    "            try:\n",
    "                if save_dir_special_root==None:\n",
    "                    save_dir_special_root= exp_dir\n",
    "                \n",
    "                save_dir_special = f'{save_dir_special_root}/{save_folder_name}'\n",
    "                run(opts= opts, save_special=save_special, save_dir_special= save_dir_special)\n",
    "            except Exception as e:\n",
    "                error_file_name = f'{exp_dir}/errors.txt'\n",
    "                write_errormsg2file(f'ERROR : {save_dir}\\n {e} \\n\\n', error_file_name)\n",
    "                print(f'ERROR : {save_dir}\\n {e} \\n\\n')\n",
    "            \n",
    "    print(f'\\n\\nCOUNT ONLY (no exps running/ deleting) : {count_only}')\n",
    "    print('count_already_trained (tot_epochs completed): ', count_already_trained)\n",
    "    print('count_train_from_begining : ', count_train_from_begining)\n",
    "    print('count_train_from_begining (after deleting existing exp) : ', count_deleted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "name= 'set1'\n",
    "\n",
    "exp_dir= f'../figs_cvpr_segmentation/{name}' #'/n/holyscratch01/wadduwage_lab/uom_Udith/results/aim2/important/exp_set1'\n",
    "save_dir_special_root = f'/n/holyscratch01/wadduwage_lab/uom_Udith/results/aim2/figs_cvpr_segmentation/{name}'\n",
    "\n",
    "#!rm -rf $exp_dir\n",
    "#!mkdir $exp_dir\n",
    "\n",
    "#!rm -rf $save_dir_special_root\n",
    "#!mkdir $save_dir_special_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_only = False\n",
    "\n",
    "device = 'cuda:0'\n",
    "lambda_scale_factors = ['8', '7', '6', '5'] #'1', '2', '3', '4', , '6', '7', '8'\n",
    "Ts= ['1'] \n",
    "rotation_lambdas= ['10000.0']\n",
    "\n",
    "exps = {\n",
    "        'DATASET.name': ['confocal'], #'mnistdigits_grid2patch'\n",
    "    \n",
    "        'MODEL.MODEL_A.rotation_lambda': rotation_lambdas,\n",
    "        'MODEL.MODEL_A.lambda_scale_factor': lambda_scale_factors, \n",
    "        'MODEL.MODEL_H.T': Ts, \n",
    "        \n",
    "        'DATASET.img_size':  ['256'],\n",
    "        'DATASET.num_samples_train': ['3000'],\n",
    "        'MODEL.MODEL_DECODER.upsample_net': ['custom_v2']} #\n",
    "\n",
    "general_opts= ['TRAIN.show_results_epoch', '5',\n",
    "                'TRAIN.epochs', '150'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps['MODEL.MODEL_H.H_init'] = ['uniformones_FourierBased']\n",
    "exps['MODEL.MODEL_H.lr_H'] = ['0.0']\n",
    "safe_do_exps(exps, general_opts, device, exp_dir = exp_dir, save_special= True, count_only= count_only, save_dir_special_root= save_dir_special_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepTFM",
   "language": "python",
   "name": "deeptfm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
