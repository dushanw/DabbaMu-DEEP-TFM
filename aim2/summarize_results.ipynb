{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "import time\n",
    "from reportlab.lib.enums import TA_JUSTIFY\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, PageBreak\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "\n",
    "\n",
    "def cartesian_coord(*arrays):\n",
    "    grid = np.meshgrid(*arrays)        \n",
    "    coord_list = [entry.ravel() for entry in grid]\n",
    "    points = np.vstack(coord_list).T\n",
    "    return points\n",
    "\n",
    "def get_available_attr(img_list):\n",
    "    attr_dict = {}\n",
    "    for img_dir in img_list:\n",
    "        for attr in img_dir.split('/')[-2].split('@'):\n",
    "            attr_name, attr_value = attr.split('(')[0], attr.split('(')[1][:-1]\n",
    "            if attr_name not in attr_dict.keys():\n",
    "                attr_dict[attr_name] = [attr_value]\n",
    "            else:\n",
    "                if attr_value not in attr_dict[attr_name]: \n",
    "                    attr_dict[attr_name].append(attr_value)\n",
    "    return attr_dict\n",
    "\n",
    "\n",
    "def filter_results(attr_dict):\n",
    "    interested_imgs = []\n",
    "    attrs = []\n",
    "    attr_names = list(attr_dict.keys())\n",
    "    attr_list= attr_dict.values()\n",
    "    \n",
    "    param_combination_list = cartesian_coord(*attr_list)\n",
    "    \n",
    "    for i in range(len(param_combination_list)):\n",
    "        param_comb= param_combination_list[i]\n",
    "        \n",
    "        attrs= []\n",
    "        for j in range(len(param_comb)):\n",
    "            attr_name = attr_names[j]\n",
    "            param_value = param_comb[j]\n",
    "            attrs.append(f'{attr_name}({param_value})')\n",
    "            \n",
    "        #print(attrs)\n",
    "        for img_dir in img_list:\n",
    "            flag=True\n",
    "            for attr in attrs:\n",
    "                #print('check : ',attr.split('('))\n",
    "                if attr.split('(')[1][:-1]=='all':\n",
    "                    flag=True\n",
    "                    continue\n",
    "                else:\n",
    "                    if attr not in img_dir:\n",
    "                        flag= False\n",
    "                        break\n",
    "            if flag==True:interested_imgs.append(img_dir)\n",
    "            #else:print(img_dir)\n",
    "    print(f'{len(interested_imgs)} images are found !!!')\n",
    "    return interested_imgs\n",
    "\n",
    "def show_results(key, dict_img_position, interested_imgs, sort_by_attr_values=None):\n",
    "    start, end = dict_img_position[key]\n",
    "\n",
    "    for img_dir in sorted(interested_imgs, key=sort_by_attr_values):\n",
    "        plt.figure(figsize = (15,5))\n",
    "        plt.imshow(plt.imread(img_dir)[start:end,:])\n",
    "        plt.title(img_dir)\n",
    "        plt.show()\n",
    "\n",
    "def sort_name_by_epoch(x):\n",
    "    return int(x.split('/')[-1].split('_')[0])\n",
    "\n",
    "def find_last_converged_result(img_dir, loss_threshold=0.05):\n",
    "    img_list = sorted(glob.glob(f\"{img_dir}/*.jpg\"),key= sort_name_by_epoch, reverse=True)\n",
    "    for img_dir in img_list:\n",
    "        loss= float(img_dir.split('(')[-1][:-5])\n",
    "        \n",
    "        img= plt.imread(img_dir)\n",
    "        is_loss_okay= loss< loss_threshold\n",
    "        is_results_okay= img[100, 300].sum()< 765\n",
    "\n",
    "        if is_loss_okay and is_results_okay:\n",
    "            return img_dir\n",
    "    \n",
    "    print(f'####   no image found : {img_dir}')\n",
    "    return None\n",
    "\n",
    "def get_metric(img_dir):\n",
    "    img_name = img_dir.split('/')[-1]\n",
    "    metrics = img_name[:-4].split('_')[1:]\n",
    "    metric_dict = {}\n",
    "    for metric in metrics:\n",
    "        metric_value = metric.split('(')[1][:-1]\n",
    "        if metric_value!='nan':metric_value=float(metric_value)\n",
    "            \n",
    "        metric_dict[metric.split('(')[0]] = metric_value\n",
    "    return metric_dict\n",
    "\n",
    "def find_best_result(img_dir, metric_name='SSIM', metric_type= 'score'): #metric_type= loss/ score\n",
    "    img_list = sorted(glob.glob(f\"{img_dir}/*.jpg\"),key= sort_name_by_epoch, reverse=True)\n",
    "    min_loss=1000\n",
    "    final_img_dir= None\n",
    "    \n",
    "    metric_list=[]\n",
    "    for img_dir in img_list:\n",
    "        metric_dict = get_metric(img_dir)\n",
    "        metric = metric_dict[metric_name]\n",
    "        if metric!='nan':metric_list.append(metric)\n",
    "        \n",
    "    min_metric= min(metric_list)\n",
    "    max_metric= max(metric_list)\n",
    "    \n",
    "    for img_dir in img_list:\n",
    "        metric_dict = get_metric(img_dir)\n",
    "        metric = metric_dict[metric_name]\n",
    "        \n",
    "        img= plt.imread(img_dir)\n",
    "        is_results_okay= img[100, 300].sum()< 765\n",
    "        \n",
    "\n",
    "        if is_results_okay and metric!='nan':\n",
    "            #loss= float(loss)\n",
    "            if metric_type== 'loss':\n",
    "                if metric<min_metric+0.005:\n",
    "                    return img_dir\n",
    "            elif metric_type== 'score':\n",
    "                if metric>max_metric-0.005:\n",
    "                    return img_dir\n",
    "                \n",
    "            \n",
    "    print(f'####   no image found : {img_dir}')\n",
    "    return None\n",
    "\n",
    "def get_img_list(img_dir = 'figs/mnistv6', mode='L1Loss', loss_threshold=0.05):\n",
    "    exp_list = sorted(glob.glob(f'{img_dir}/*@*'))\n",
    "    \n",
    "    img_dirs=[]\n",
    "    for idx in range(len(exp_list)):\n",
    "        #if idx>102:break\n",
    "        exp_dir = exp_list[idx]\n",
    "            \n",
    "        if mode=='last_converged':img_dir = find_last_converged_result(exp_dir, loss_threshold)\n",
    "        elif mode=='L1Loss':img_dir = find_best_result(exp_dir, metric_name='L1Loss', metric_type= 'loss')\n",
    "        elif mode=='MSE':img_dir = find_best_result(exp_dir, metric_name='MSE', metric_type= 'loss')\n",
    "        elif mode=='SSIM':img_dir = find_best_result(exp_dir, metric_name='SSIM', metric_type= 'score')\n",
    "        elif mode=='SSIM5':img_dir = find_best_result(exp_dir, metric_name='SSIM5', metric_type= 'score')\n",
    "        elif mode=='SSIM11':img_dir = find_best_result(exp_dir, metric_name='SSIM11', metric_type= 'score')\n",
    "        \n",
    "        if idx%100==0:\n",
    "            print(f'{idx+1}/{len(exp_list)} : {img_dir}')\n",
    "        \n",
    "        # exceptions\n",
    "        #if idx==343:img_dir = find_last_converged_result(exp_dir, 0.130)\n",
    "        ##\n",
    "        \n",
    "        if img_dir==None:\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        img_dirs.append(img_dir)\n",
    "    print(f'len img dirs : {len(img_dirs)}')\n",
    "    return img_dirs\n",
    "    \n",
    "    \n",
    "def sort_by_attr_values(img_dir):\n",
    "    img_dir= img_dir.split('/')[-2]\n",
    "    values=[]\n",
    "    for attr in img_dir.split(')'):\n",
    "        if attr== '':continue\n",
    "        values.append(float(attr.split('(')[1]))\n",
    "    return values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_imgs2pdf(img_dir_list, sorting_function, pdf_filename, attr_dict=None):\n",
    "    img_dir_list_sorted = sorted(img_dir_list, key = sorting_function)\n",
    "    doc = SimpleDocTemplate(pdf_filename,pagesize=letter,\n",
    "                            rightMargin=72,leftMargin=72,\n",
    "                            topMargin=72,bottomMargin=18)\n",
    "    Story=[]\n",
    "    \n",
    "    styles=getSampleStyleSheet()\n",
    "    styles.add(ParagraphStyle(name='Justify', alignment=TA_JUSTIFY))\n",
    "    \n",
    "    if attr_dict!=None:\n",
    "        title = '<font size=\"25\">%s</font>' % \"Experiment hyperparameters\"\n",
    "        Story.append(Paragraph(title, styles[\"Normal\"]))\n",
    "        Story.append(Spacer(1, 50))\n",
    "        \n",
    "        for (k, v) in attr_dict.items():\n",
    "            entry = f'{str(k)} : {str(sorted(v, key= float))}'\n",
    "            attr = '<font size=\"15\">%s</font>' % entry\n",
    "            Story.append(Paragraph(attr, styles[\"Normal\"], bulletText='-'))\n",
    "            Story.append(Spacer(1, 30))\n",
    "        \n",
    "        Story.append(PageBreak())\n",
    "        \n",
    "\n",
    "    for idx in range(len(img_dir_list)):\n",
    "        img_name= img_dir_list_sorted[idx]\n",
    "        \n",
    "        img_dir_name= img_name.split('/')[-2]\n",
    "        ptext = '<font size=\"7\">%s</font>' % img_dir_name\n",
    "        Story.append(Paragraph(ptext, styles[\"Normal\"])) \n",
    "        Story.append(Spacer(1, 10))\n",
    "        \n",
    "        ptext = '<font size=\"12\">%s</font>' % img_name\n",
    "        Story.append(Paragraph(ptext, styles[\"Normal\"])) \n",
    "        Story.append(Spacer(1, 30))\n",
    "        \n",
    "        im = Image(img_name, 8*inch, 8*inch)\n",
    "        Story.append(im)\n",
    "        Story.append(PageBreak())\n",
    "    doc.build(Story)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate heat maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metric_map(dict_, metric_name='SSIM', interested_key1= 'T', interested_key2 = 'lambda_scale_factor', override_dict= {}):\n",
    "    for key_ in override_dict:\n",
    "        dict_[key_] = override_dict[key_]\n",
    "    \n",
    "    interested_imgs = filter_results(dict_)\n",
    "    \n",
    "    ax1_labels = sorted(dict_[interested_key1], key =float)\n",
    "    ax2_labels = sorted(dict_[interested_key2], key =float)\n",
    "            \n",
    "    metric_map = np.ones((len(ax1_labels),len(ax2_labels)), dtype='float')\n",
    "    \n",
    "    def imgdir2metric(img_name):return get_metric(img_name)[metric_name]\n",
    "    \n",
    "    for i in range(len(ax1_labels)):\n",
    "        ax1_vals = ax1_labels[i]\n",
    "        for j in range(len(ax2_labels)):\n",
    "            ax2_vals = ax2_labels[j]\n",
    "\n",
    "            valid_img_dirs=[]\n",
    "            for img_dir in interested_imgs:\n",
    "                if f'{interested_key1}({ax1_vals})' in img_dir and f'{interested_key2}({ax2_vals})' in img_dir:valid_img_dirs.append(img_dir)\n",
    "\n",
    "\n",
    "            sorted_valid_img_dirs= sorted(valid_img_dirs, key= imgdir2metric)\n",
    "            #print(sorted_valid_img_dirs)\n",
    "            selected_img_dir = sorted_valid_img_dirs[0]\n",
    "\n",
    "            metric_dict = get_metric(selected_img_dir)\n",
    "            metric_map[i, j]= metric_dict[metric_name]\n",
    "                \n",
    "    return metric_map, ax1_labels, ax2_labels\n",
    "\n",
    "def plot_heatmap(metric_map_highlrH, metric_map_lowlrH, vmin, vmax, x_ticks, y_ticks, interested_key1, interested_key2, override_dict, metric_name, save_dir):\n",
    "    plt.figure(figsize= (15,3))\n",
    "    plt.subplot(1,2,1)\n",
    "    ax = sns.heatmap(metric_map_highlrH, linewidth=0.5, annot=True, vmin=vmin, vmax= vmax, fmt= '.5f')\n",
    "    plt.xticks(np.arange(len(y_ticks))+0.5, y_ticks, rotation=0)\n",
    "    plt.xlabel(interested_key2)\n",
    "    plt.yticks(np.arange(len(x_ticks))+0.5, x_ticks, rotation=0)\n",
    "    plt.ylabel(interested_key1)\n",
    "    plt.title('Ht is learnable')\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    ax = sns.heatmap(metric_map_lowlrH, linewidth=0.5, annot=True, vmin=vmin, vmax= vmax, fmt= '.5f')\n",
    "    plt.xticks(np.arange(len(y_ticks))+0.5, y_ticks, rotation=0)\n",
    "    plt.xlabel(interested_key2)\n",
    "    plt.yticks(np.arange(len(x_ticks))+0.5, x_ticks, rotation=0)\n",
    "    plt.ylabel(interested_key1)\n",
    "    plt.title('Ht is fixed')\n",
    "    \n",
    "    suptit = f'{metric_name} -- '\n",
    "    overrides= ''\n",
    "    for key_, val_ in override_dict.items():\n",
    "        suptit+=f'{key_} : {val_} | '\n",
    "        overrides += f'{key_}({val_})@'\n",
    "    \n",
    "    suptit = suptit[:-3] \n",
    "    overrides= overrides[:-1]\n",
    "    \n",
    "    plt.suptitle(suptit, y= 1.1)\n",
    "    \n",
    "    if save_dir!=None:\n",
    "        save_dir = f'{save_dir}/heatmaps'\n",
    "        \n",
    "        try:os.mkdir(save_dir)\n",
    "        except:pass\n",
    "        \n",
    "        np.save(f'{save_dir}/{metric_name}@@{overrides}@@highlrH.npy', metric_map_highlrH)\n",
    "        np.save(f'{save_dir}/{metric_name}@@{overrides}@@lowlrH.npy', metric_map_lowlrH)\n",
    "        \n",
    "        plt.savefig(f'{save_dir}/{metric_name}@@{overrides}.jpg', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_all_heat_maps(attr_dict_highlrH, attr_dict_lowlrH, interested_key1, interested_key2, override_dict, metric_name= 'SSIM', save_dir =None):\n",
    "    map_highlrH, xticks_highlrH, yticks_highlrH = create_metric_map(attr_dict_highlrH, metric_name=metric_name, interested_key1= interested_key1, interested_key2 = interested_key2, override_dict= override_dict)\n",
    "    map_lowlrH, xticks_lowlrH, yticks_lowlrH = create_metric_map(attr_dict_lowlrH, metric_name=metric_name, interested_key1= interested_key1, interested_key2 = interested_key2, override_dict= override_dict)\n",
    "\n",
    "    \n",
    "    assert xticks_highlrH== xticks_lowlrH, 'Missing lowLR/ highHR images'\n",
    "    assert yticks_highlrH== yticks_lowlrH, 'Missing lowLR/ highHR images'\n",
    "\n",
    "    vmin = min(map_highlrH.min(), map_lowlrH.min())\n",
    "    vmax =  max(map_highlrH.max(), map_lowlrH.max())\n",
    "\n",
    "    plot_heatmap(map_highlrH, map_lowlrH, vmin, vmax, xticks_highlrH, yticks_highlrH, interested_key1, interested_key2, override_dict, metric_name, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "dict_img_position = {\n",
    "    'main':[0, 200],\n",
    "    'ht':[200, 650],\n",
    "    'loss':[650, 920],\n",
    "    'overall_results':[930, 1150]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/108 : figs/mnistv11/img_size(64)@T(1)@rotation_lambda(10.0)@lr_H(0.0)@lambda_scale_factor(1)/150_L1Loss(0.0301379)_MSE(0.0278166)_SSIM11(0.7413925)_SSIM5(0.7230884).jpg\n",
      "101/108 : figs/mnistv11/img_size(64)@T(8)@rotation_lambda(100.0)@lr_H(1.0)@lambda_scale_factor(2)/150_L1Loss(0.0170246)_MSE(0.0071603)_SSIM11(0.8392136)_SSIM5(0.8105979).jpg\n",
      "len img dirs : 108\n",
      "108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'img_size': ['64'],\n",
       " 'T': ['1', '16', '2', '32', '4', '8'],\n",
       " 'rotation_lambda': ['10.0', '100.0', '1000.0'],\n",
       " 'lr_H': ['0.0', '1.0'],\n",
       " 'lambda_scale_factor': ['1', '2', '3']}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modes = ['L1Loss', 'MSE', 'SSIM', 'SSIM11', 'SSIM5', 'last_converged']\n",
    "mode = modes[4]\n",
    "exp_set_dir = 'figs/mnistv11'\n",
    "\n",
    "img_list = get_img_list(img_dir = exp_set_dir, mode=mode)\n",
    "\n",
    "print(len(img_list))\n",
    "get_available_attr(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 images are found !!!\n",
      "available keys : ['main', 'ht', 'loss', 'overall_results']\n"
     ]
    }
   ],
   "source": [
    "dict_ = {'img_size': ['64'],\n",
    " 'T': ['1', '16', '2', '32', '4', '8'],\n",
    " 'rotation_lambda': ['10.0', '100.0', '1000.0'],\n",
    " 'lr_H': ['0.0', '1.0'],\n",
    " 'lambda_scale_factor': ['1', '2', '3']}\n",
    "\n",
    "interested_imgs = filter_results(dict_)\n",
    "print(f'available keys : {list(dict_img_position.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results('main', dict_img_position, interested_imgs,  sort_by_attr_values)\n",
    "show_results('loss', dict_img_position, interested_imgs,  sort_by_attr_values)\n",
    "show_results('ht', dict_img_position, interested_imgs,  sort_by_attr_values)\n",
    "#show_results('overall_results', dict_img_position, interested_imgs,  sort_by_attr_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import shutil\n",
    "#try:shutil.rmtree(f'{exp_set_dir}/_results_summaries')\n",
    "#except:pass\n",
    "#os.mkdir(f'{exp_set_dir}/_results_summaries')\n",
    "\n",
    "save_imgs2pdf(interested_imgs, sorting_function= sort_by_attr_values, pdf_filename=f'{exp_set_dir}/_results_summaries/results_{mode}.pdf', attr_dict= dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img_size': ['64'],\n",
       " 'T': ['1', '16', '2', '32', '4', '8'],\n",
       " 'rotation_lambda': ['10.0', '100.0', '1000.0'],\n",
       " 'lr_H': ['0.0', '1.0'],\n",
       " 'lambda_scale_factor': ['1', '2', '3']}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BELOW attr_dict_highlrH, attr_dict_lowlrH -> ONLY CONTAIN KEYS: lr_H, interested_key1, interested_key2 || Other keys -> goes into override dicts !!!\n",
    "\n",
    "attr_dict_lowlrH= {\n",
    " 'T': ['1', '16', '2', '32', '4', '8'],\n",
    " 'lr_H': ['0.0'],\n",
    " 'lambda_scale_factor': ['1', '2', '3']}\n",
    "\n",
    "attr_dict_highlrH = {\n",
    " 'T': ['1', '16', '2', '32', '4', '8'],\n",
    " 'lr_H': ['1.0'],\n",
    " 'lambda_scale_factor': ['1', '2', '3']}\n",
    "\n",
    "override_dict=  {'rotation_lambda': ['1000.0'], 'img_size': ['64']} #where this used: 1. to change input dicts, 2. visualize in heatmap title\n",
    "\n",
    "save_dir= exp_set_dir\n",
    "plot_all_heat_maps(attr_dict_highlrH, attr_dict_lowlrH, interested_key1 = 'T', interested_key2= 'lambda_scale_factor', override_dict=override_dict, metric_name= mode, save_dir =save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_sort_function(heatmap_dir):\n",
    "    attrs = heatmap_dir[:-4].split('/')[-1].split('@')[2:]\n",
    "    attrs.reverse()\n",
    "    \n",
    "    metric = heatmap_dir[:-4].split('/')[-1].split('@')[0]\n",
    "    values = []\n",
    "    \n",
    "    for attr in attrs:\n",
    "        try:values.append(float(attr.split('(')[1][:-1]))\n",
    "        except:values.append(list(map(float, eval(attr.split('(')[1][:-1]))))\n",
    "    values.append(metric)\n",
    "    return values\n",
    "\n",
    "def save_heatmaps2pdf(heatmap_dir, heatmap_sort_function, pdf_filename):\n",
    "    heatmap_dir_list= glob.glob(f'{heatmap_dir}/*.jpg')\n",
    "    heatmap_dir_list_sorted = sorted(heatmap_dir_list, key = heatmap_sort_function)\n",
    "    doc = SimpleDocTemplate(pdf_filename,pagesize=letter,\n",
    "                            rightMargin=72,leftMargin=72,\n",
    "                            topMargin=72,bottomMargin=18)\n",
    "    Story=[]\n",
    "    \n",
    "    styles=getSampleStyleSheet()\n",
    "    styles.add(ParagraphStyle(name='Justify', alignment=TA_JUSTIFY))\n",
    "        \n",
    "\n",
    "    for idx in range(len(heatmap_dir_list_sorted)):\n",
    "        if idx!=0 and idx%3==0:Story.append(PageBreak())\n",
    "        img_name= heatmap_dir_list_sorted[idx]\n",
    "        \n",
    "        ptext = '<font size=\"12\">%s</font>' % img_name.split('/')[-1]\n",
    "        Story.append(Paragraph(ptext, styles[\"Normal\"])) \n",
    "        Story.append(Spacer(1, 10))\n",
    "        \n",
    "        im = Image(img_name, 8*inch, 2*inch)\n",
    "        Story.append(im)\n",
    "        Story.append(Spacer(1, 30))\n",
    "        \n",
    "    doc.build(Story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_heatmaps2pdf(f'{exp_set_dir}/heatmaps', heatmap_sort_function, f'{exp_set_dir}/heatmaps/summary.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepTFM",
   "language": "python",
   "name": "deeptfm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
