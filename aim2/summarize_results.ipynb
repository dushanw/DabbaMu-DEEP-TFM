{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "import time\n",
    "from reportlab.lib.enums import TA_JUSTIFY\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, PageBreak\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "\n",
    "\n",
    "def cartesian_coord(*arrays):\n",
    "    grid = np.meshgrid(*arrays)        \n",
    "    coord_list = [entry.ravel() for entry in grid]\n",
    "    points = np.vstack(coord_list).T\n",
    "    return points\n",
    "\n",
    "def get_available_attr(img_list):\n",
    "    attr_dict = {}\n",
    "    for img_dir in img_list:\n",
    "        for attr in img_dir.split('/')[-2].split('@'):\n",
    "            attr_name, attr_value = attr.split('(')[0], attr.split('(')[1][:-1]\n",
    "            if attr_name not in attr_dict.keys():\n",
    "                attr_dict[attr_name] = [attr_value]\n",
    "            else:\n",
    "                if attr_value not in attr_dict[attr_name]: \n",
    "                    attr_dict[attr_name].append(attr_value)\n",
    "    return attr_dict\n",
    "\n",
    "\n",
    "def filter_results(attr_dict):\n",
    "    interested_imgs = []\n",
    "    attrs = []\n",
    "    attr_names = list(attr_dict.keys())\n",
    "    attr_list= attr_dict.values()\n",
    "    \n",
    "    param_combination_list = cartesian_coord(*attr_list)\n",
    "    \n",
    "    for i in range(len(param_combination_list)):\n",
    "        param_comb= param_combination_list[i]\n",
    "        \n",
    "        attrs= []\n",
    "        for j in range(len(param_comb)):\n",
    "            attr_name = attr_names[j]\n",
    "            param_value = param_comb[j]\n",
    "            attrs.append(f'{attr_name}({param_value})')\n",
    "            \n",
    "        #print(attrs)\n",
    "        for img_dir in img_list:\n",
    "            flag=True\n",
    "            for attr in attrs:\n",
    "                #print('check : ',attr.split('('))\n",
    "                if attr.split('(')[1][:-1]=='all':\n",
    "                    flag=True\n",
    "                    continue\n",
    "                else:\n",
    "                    if attr not in img_dir:\n",
    "                        flag= False\n",
    "                        break\n",
    "            if flag==True:interested_imgs.append(img_dir)\n",
    "            #else:print(img_dir)\n",
    "    print(f'{len(interested_imgs)} images are found !!!')\n",
    "    return interested_imgs\n",
    "\n",
    "def show_results(key, dict_img_position, interested_imgs, sort_by_attr_values=None):\n",
    "    start, end = dict_img_position[key]\n",
    "\n",
    "    for img_dir in sorted(interested_imgs, key=sort_by_attr_values):\n",
    "        plt.figure(figsize = (15,5))\n",
    "        plt.imshow(plt.imread(img_dir)[start:end,:])\n",
    "        plt.title(img_dir)\n",
    "        plt.show()\n",
    "\n",
    "def sort_name_by_epoch(x):\n",
    "    return int(x.split('/')[-1].split('_')[0])\n",
    "\n",
    "def find_last_converged_result(img_dir, loss_threshold=0.05):\n",
    "    img_list = sorted(glob.glob(f\"{img_dir}/*.jpg\"),key= sort_name_by_epoch, reverse=True)\n",
    "    for img_dir in img_list:\n",
    "        loss= float(img_dir.split('(')[-1][:-5])\n",
    "        \n",
    "        img= plt.imread(img_dir)\n",
    "        is_loss_okay= loss< loss_threshold\n",
    "        is_results_okay= img[100, 300].sum()< 765\n",
    "\n",
    "        if is_loss_okay and is_results_okay:\n",
    "            return img_dir\n",
    "    \n",
    "    print(f'####   no image found : {img_dir}')\n",
    "    return None\n",
    "\n",
    "def get_metric(img_dir):\n",
    "    img_name = img_dir.split('/')[-1]\n",
    "    metrics = img_name[:-4].split('_')[1:]\n",
    "    metric_dict = {}\n",
    "    for metric in metrics:\n",
    "        metric_value = metric.split('(')[1][:-1]\n",
    "        if metric_value!='nan':metric_value=float(metric_value)\n",
    "            \n",
    "        metric_dict[metric.split('(')[0]] = metric_value\n",
    "    return metric_dict\n",
    "\n",
    "def find_best_result(img_dir, metric_name='SSIM', metric_type= 'score'): #metric_type= loss/ score\n",
    "    img_list = sorted(glob.glob(f\"{img_dir}/*.jpg\"),key= sort_name_by_epoch, reverse=True)\n",
    "    min_loss=1000\n",
    "    final_img_dir= None\n",
    "    \n",
    "    metric_list=[]\n",
    "    for img_dir in img_list:\n",
    "        metric_dict = get_metric(img_dir)\n",
    "        metric = metric_dict[metric_name]\n",
    "        if metric!='nan':metric_list.append(metric)\n",
    "        \n",
    "    min_metric= min(metric_list)\n",
    "    max_metric= max(metric_list)\n",
    "    \n",
    "    for img_dir in img_list:\n",
    "        metric_dict = get_metric(img_dir)\n",
    "        metric = metric_dict[metric_name]\n",
    "        \n",
    "        img= plt.imread(img_dir)\n",
    "        is_results_okay= img[100, 300].sum()< 765\n",
    "        \n",
    "\n",
    "        if is_results_okay and metric!='nan':\n",
    "            #loss= float(loss)\n",
    "            if metric_type== 'loss':\n",
    "                if metric<min_metric+0.005:\n",
    "                    return img_dir\n",
    "            elif metric_type== 'score':\n",
    "                if metric>max_metric-0.005:\n",
    "                    return img_dir\n",
    "                \n",
    "            \n",
    "    print(f'####   no image found : {img_dir}')\n",
    "    return None\n",
    "\n",
    "def get_img_list(img_dir = 'figs/mnistv6', mode='L1Loss', loss_threshold=0.05):\n",
    "    exp_list = sorted(glob.glob(f'{img_dir}/*@*'))\n",
    "    \n",
    "    img_dirs=[]\n",
    "    for idx in range(len(exp_list)):\n",
    "        #if idx>102:break\n",
    "        exp_dir = exp_list[idx]\n",
    "            \n",
    "        if mode=='last_converged':img_dir = find_last_converged_result(exp_dir, loss_threshold)\n",
    "        elif mode=='L1Loss':img_dir = find_best_result(exp_dir, metric_name='L1Loss', metric_type= 'loss')\n",
    "        elif mode=='MSE':img_dir = find_best_result(exp_dir, metric_name='MSE', metric_type= 'loss')\n",
    "        elif mode=='SSIM':img_dir = find_best_result(exp_dir, metric_name='SSIM', metric_type= 'score')\n",
    "        \n",
    "        if idx%100==0:\n",
    "            print(f'{idx+1}/{len(exp_list)} : {img_dir}')\n",
    "        \n",
    "        # exceptions\n",
    "        #if idx==343:img_dir = find_last_converged_result(exp_dir, 0.130)\n",
    "        ##\n",
    "        \n",
    "        if img_dir==None:\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        img_dirs.append(img_dir)\n",
    "    print(f'len img dirs : {len(img_dirs)}')\n",
    "    return img_dirs\n",
    "    \n",
    "    \n",
    "def sort_by_attr_values(img_dir):\n",
    "    img_dir= img_dir.split('/')[-2]\n",
    "    values=[]\n",
    "    for attr in img_dir.split(')'):\n",
    "        if attr== '':continue\n",
    "        values.append(float(attr.split('(')[1]))\n",
    "    return values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_imgs2pdf(img_dir_list, sorting_function, pdf_filename, attr_dict=None):\n",
    "    img_dir_list_sorted = sorted(img_dir_list, key = sorting_function)\n",
    "    doc = SimpleDocTemplate(pdf_filename,pagesize=letter,\n",
    "                            rightMargin=72,leftMargin=72,\n",
    "                            topMargin=72,bottomMargin=18)\n",
    "    Story=[]\n",
    "    \n",
    "    styles=getSampleStyleSheet()\n",
    "    styles.add(ParagraphStyle(name='Justify', alignment=TA_JUSTIFY))\n",
    "    \n",
    "    if attr_dict!=None:\n",
    "        title = '<font size=\"25\">%s</font>' % \"Experiment hyperparameters\"\n",
    "        Story.append(Paragraph(title, styles[\"Normal\"]))\n",
    "        Story.append(Spacer(1, 50))\n",
    "        \n",
    "        for (k, v) in attr_dict.items():\n",
    "            entry = f'{str(k)} : {str(sorted(v, key= float))}'\n",
    "            attr = '<font size=\"15\">%s</font>' % entry\n",
    "            Story.append(Paragraph(attr, styles[\"Normal\"], bulletText='-'))\n",
    "            Story.append(Spacer(1, 30))\n",
    "        \n",
    "        Story.append(PageBreak())\n",
    "        \n",
    "\n",
    "    for idx in range(len(img_dir_list)):\n",
    "        img_name= img_dir_list_sorted[idx]\n",
    "        \n",
    "        img_dir_name= img_name.split('/')[-2]\n",
    "        ptext = '<font size=\"7\">%s</font>' % img_dir_name\n",
    "        Story.append(Paragraph(ptext, styles[\"Normal\"])) \n",
    "        Story.append(Spacer(1, 10))\n",
    "        \n",
    "        ptext = '<font size=\"12\">%s</font>' % img_name\n",
    "        Story.append(Paragraph(ptext, styles[\"Normal\"])) \n",
    "        Story.append(Spacer(1, 30))\n",
    "        \n",
    "        im = Image(img_name, 8*inch, 8*inch)\n",
    "        Story.append(im)\n",
    "        Story.append(PageBreak())\n",
    "    doc.build(Story)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate heat maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metric_map(dict_, lambda_scale_factor=1, img_size=32, metric_name='SSIM'): \n",
    "    dict_['lambda_scale_factor']= [str(lambda_scale_factor)]\n",
    "    dict_['img_size']= [str(img_size)]\n",
    "    \n",
    "    print('lambda scale factor : ',dict_['lambda_scale_factor'])\n",
    "    print('img_size : ',dict_['img_size'])\n",
    "    \n",
    "    interested_imgs = filter_results(dict_)\n",
    "\n",
    "    Ts= sorted(dict_['T'], key =float)\n",
    "    rotation_lambdas = sorted(dict_['rotation_lambda'], key= float)\n",
    "    \n",
    "    metric_map = np.ones((len(Ts),len(rotation_lambdas)), dtype='float')\n",
    "    \n",
    "    def imgdir2metric(img_name):return get_metric(img_name)[metric_name]\n",
    "    \n",
    "    for i in range(len(Ts)):\n",
    "        T= Ts[i]\n",
    "        for j in range(len(rotation_lambdas)):\n",
    "            rotation_lambda= rotation_lambdas[j]\n",
    "\n",
    "            valid_img_dirs=[]\n",
    "            for img_dir in interested_imgs:\n",
    "                if f'T({T})' in img_dir and f'rotation_lambda({rotation_lambda})' in img_dir:valid_img_dirs.append(img_dir)\n",
    "\n",
    "\n",
    "            sorted_valid_img_dirs= sorted(valid_img_dirs, key= imgdir2metric)\n",
    "            selected_img_dir = sorted_valid_img_dirs[0]\n",
    "\n",
    "            metric_dict = get_metric(selected_img_dir)\n",
    "            metric_map[i, j]= metric_dict[metric_name]\n",
    "                \n",
    "    return metric_map, Ts, rotation_lambdas\n",
    "\n",
    "def plot_heatmap(metric_map_highlrH, metric_map_lowlrH, vmin, vmax, x_ticks, y_ticks, lambda_scale_factor, img_size, metric_name, save_dir):\n",
    "    plt.figure(figsize= (15,3))\n",
    "    plt.subplot(1,2,1)\n",
    "    ax = sns.heatmap(metric_map_highlrH, linewidth=0.5, annot=True, vmin=vmin, vmax= vmax)\n",
    "    plt.xticks(range(len(y_ticks)), y_ticks, rotation=0)\n",
    "    plt.xlabel('K')\n",
    "    plt.yticks(range(len(x_ticks)), x_ticks, rotation=0)\n",
    "    plt.ylabel('T')\n",
    "    plt.title('Ht is learnable')\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    ax = sns.heatmap(metric_map_lowlrH, linewidth=0.5, annot=True, vmin=vmin, vmax= vmax)\n",
    "    plt.xticks(range(len(y_ticks)), y_ticks, rotation=0)\n",
    "    plt.xlabel('K')\n",
    "    plt.yticks(range(len(x_ticks)), x_ticks, rotation=0)\n",
    "    plt.ylabel('T')\n",
    "    plt.title('Ht is fixed')\n",
    "    \n",
    "    plt.suptitle(f'{metric_name} -- lambda scale factor : {lambda_scale_factor} | img_size : {img_size}')\n",
    "    \n",
    "    if save_dir!=None:\n",
    "        save_dir = f'{save_dir}/heatmaps'\n",
    "        \n",
    "        try:os.mkdir(save_dir)\n",
    "        except:pass\n",
    "        \n",
    "        plt.savefig(f'{save_dir}/{metric_name}@@lambda_scale_factor({lambda_scale_factor})@img_size({img_size}).jpg')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_all_heat_maps(attr_dict_highlrH, attr_dict_lowlrH, lambda_scale_factor=1, img_size=32, metric_name= 'SSIM', save_dir =None):\n",
    "    map_highlrH, xticks_highlrH, yticks_highlrH = create_metric_map(attr_dict_highlrH, lambda_scale_factor=lambda_scale_factor, img_size= img_size, metric_name= metric_name)\n",
    "    map_lowlrH, xticks_lowlrH, yticks_lowlrH = create_metric_map(attr_dict_lowlrH, lambda_scale_factor=lambda_scale_factor, img_size= img_size, metric_name= metric_name)\n",
    "    \n",
    "    assert xticks_highlrH== xticks_lowlrH, 'Missing lowLR/ highHR images'\n",
    "    assert yticks_highlrH== yticks_lowlrH, 'Missing lowLR/ highHR images'\n",
    "\n",
    "    vmin = min(map_highlrH.min(), map_lowlrH.min())\n",
    "    vmax =  max(map_highlrH.max(), map_lowlrH.max())\n",
    "\n",
    "    plot_heatmap(map_highlrH, map_lowlrH, vmin, vmax, xticks_highlrH, yticks_highlrH, lambda_scale_factor, img_size, metric_name, save_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "dict_img_position = {\n",
    "    'main':[0, 200],\n",
    "    'ht':[200, 650],\n",
    "    'loss':[650, 920],\n",
    "    'overall_results':[930, 1150]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncount=0\\nnew_names = []\\nfor dir_ in os.listdir('figs/mnistv6/'):\\n    splitted= dir_.split('@')\\n    new_name= dir_\\n    if 'img_size' in splitted[0] and 'img_size' in splitted[1]:\\n        new_name = '@'.join(splitted[1:])\\n\\n        new_dir_name = f'figs/mnistv6/{new_name}'\\n        \\n        os.rename(f'figs/mnistv6/{dir_}', new_dir_name)\\n    new_names.append(new_name)\\n    if new_name.split('@')[0]=='img_size(32)':count+=1\\n    else:print(new_name)\\nprint(count)\\n\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "count=0\n",
    "new_names = []\n",
    "for dir_ in os.listdir('figs/mnistv6/'):\n",
    "    splitted= dir_.split('@')\n",
    "    new_name= dir_\n",
    "    if 'img_size' in splitted[0] and 'img_size' in splitted[1]:\n",
    "        new_name = '@'.join(splitted[1:])\n",
    "\n",
    "        new_dir_name = f'figs/mnistv6/{new_name}'\n",
    "        \n",
    "        os.rename(f'figs/mnistv6/{dir_}', new_dir_name)\n",
    "    new_names.append(new_name)\n",
    "    if new_name.split('@')[0]=='img_size(32)':count+=1\n",
    "    else:print(new_name)\n",
    "print(count)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = ['L1Loss', 'MSE', 'SSIM', 'last_converged']\n",
    "mode = modes[2]\n",
    "exp_set_dir = 'figs/mnistv8'\n",
    "\n",
    "img_list = get_img_list(img_dir = exp_set_dir, mode=mode)\n",
    "#img_list = glob.glob('figs/mnistv6/*/10_*.jpg')\n",
    "\n",
    "print(len(img_list))\n",
    "get_available_attr(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = {'img_size': ['128', '32', '64'],\n",
    " 'T': ['1', '16', '2', '32', '4', '8'],\n",
    " 'rotation_lambda': ['10.0', '100.0', '1000.0'],\n",
    " 'lr_H': ['0.0', '0.0001', '0.001', '0.01', '0.1', '1.0', '10.0'],\n",
    " 'lambda_scale_factor': ['1', '2', '3', '4']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512 images are found !!!\n",
      "available keys : ['main', 'ht', 'loss', 'overall_results']\n"
     ]
    }
   ],
   "source": [
    "interested_imgs = filter_results(dict_)\n",
    "print(f'available keys : {list(dict_img_position.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results('main', dict_img_position, interested_imgs,  sort_by_attr_values)\n",
    "show_results('loss', dict_img_position, interested_imgs,  sort_by_attr_values)\n",
    "show_results('ht', dict_img_position, interested_imgs,  sort_by_attr_values)\n",
    "#show_results('overall_results', dict_img_position, interested_imgs,  sort_by_attr_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_imgs2pdf(interested_imgs, sorting_function= sort_by_attr_values, pdf_filename=f'{exp_set_dir}/_results_summaries/results_{mode}.pdf', attr_dict= dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_dict_highlrH = {\n",
    "         'lr_H': ['0.0001', '0.001', '0.01', '0.1', '1.0', '10.0'],\n",
    "         'T': ['1', '2', '4', '8', '16', '32'],\n",
    "         'rotation_lambda': ['10.0', '100.0', '1000.0']}\n",
    "\n",
    "attr_dict_lowlrH = {\n",
    "         'lr_H': ['0.0'],\n",
    "         'T': ['1', '2', '4', '8', '16', '32'],\n",
    "         'rotation_lambda': ['10.0', '100.0', '1000.0']}\n",
    "\n",
    "for img_size in [32, 64, 128]:\n",
    "    for lambda_scale_factor in [1,2,3,4]:\n",
    "        plot_all_heat_maps(attr_dict_highlrH, attr_dict_lowlrH, lambda_scale_factor=lambda_scale_factor, img_size= img_size, metric_name=mode, save_dir= exp_set_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1,2,3].reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_sort_function(heatmap_dir):\n",
    "    attrs = heatmap_dir[:-4].split('/')[-1].split('@')[2:]\n",
    "    attrs.reverse()\n",
    "    \n",
    "    metric = heatmap_dir[:-4].split('/')[-1].split('@')[0]\n",
    "    values = [metric]\n",
    "    for attr in attrs:\n",
    "        values.append(float(attr.split('(')[1][:-1]))\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_heatmaps2pdf(heatmap_dir, heatmap_sort_function, pdf_filename):\n",
    "    heatmap_dir_list= glob.glob(f'{heatmap_dir}/*.jpg')\n",
    "    heatmap_dir_list_sorted = sorted(heatmap_dir_list, key = heatmap_sort_function)\n",
    "    doc = SimpleDocTemplate(pdf_filename,pagesize=letter,\n",
    "                            rightMargin=72,leftMargin=72,\n",
    "                            topMargin=72,bottomMargin=18)\n",
    "    Story=[]\n",
    "    \n",
    "    styles=getSampleStyleSheet()\n",
    "    styles.add(ParagraphStyle(name='Justify', alignment=TA_JUSTIFY))\n",
    "        \n",
    "\n",
    "    for idx in range(len(heatmap_dir_list_sorted)):\n",
    "        if idx!=0 and idx%3==0:Story.append(PageBreak())\n",
    "        img_name= heatmap_dir_list_sorted[idx]\n",
    "        \n",
    "        ptext = '<font size=\"12\">%s</font>' % img_name.split('/')[-1]\n",
    "        Story.append(Paragraph(ptext, styles[\"Normal\"])) \n",
    "        Story.append(Spacer(1, 10))\n",
    "        \n",
    "        im = Image(img_name, 9*inch, 2*inch)\n",
    "        Story.append(im)\n",
    "        Story.append(Spacer(1, 30))\n",
    "        \n",
    "    doc.build(Story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_heatmaps2pdf('figs/mnistv8/heatmaps', heatmap_sort_function, 'figs/mnistv8/heatmaps/summary.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepTFM",
   "language": "python",
   "name": "deeptfm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
